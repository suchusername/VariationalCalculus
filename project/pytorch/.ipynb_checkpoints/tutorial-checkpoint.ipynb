{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorchZeroToAll course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Backpropogaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return x * w\n",
    "\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0488], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for it in range(10):\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        L = loss(x_val, y_val)\n",
    "        L.backward()\n",
    "        w.data = w.data - 0.01 * w.grad.data\n",
    "        # manually setting gradient data to 0, because pytorch adds the new grad data to already existing one\n",
    "        w.grad.data.zero_()\n",
    "        \n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.tensor([1.0, 2.0, 3.0, 4.0]).resize_((4,1))\n",
    "y_data = torch.tensor([2.0, 4.0, 6.0, 8.0]).resize_((4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    y_pred = model(x_data)\n",
    "    L = loss(y_pred, y_data)\n",
    "    optimizer.zero_grad()\n",
    "    L.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.0000]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.tensor([[5.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deep networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DESCR', 'images', 'data', 'target_names', 'target'])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = load_digits()\n",
    "raw_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 64]) torch.Size([1797, 10])\n"
     ]
    }
   ],
   "source": [
    "x_data = torch.tensor(raw_data['data']).float()\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(raw_data['target'])\n",
    "y_data = torch.tensor(lb.transform(raw_data['target'])).float()\n",
    "print(x_data.size(), y_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DigitsNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(64,16)\n",
    "        self.linear2 = torch.nn.Linear(16,10)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.sigmoid(self.linear1(x))\n",
    "        y_pred = self.sigmoid(self.linear2(out1))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DigitsNet()\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200: loss = 0.08980939537286758\n",
      "Iteration 400: loss = 0.0895000547170639\n",
      "Iteration 600: loss = 0.08901990950107574\n",
      "Iteration 800: loss = 0.08833164721727371\n",
      "Iteration 1000: loss = 0.08706165105104446\n",
      "Iteration 1200: loss = 0.08490695059299469\n",
      "Iteration 1400: loss = 0.08174560219049454\n",
      "Iteration 1600: loss = 0.07799414545297623\n",
      "Iteration 1800: loss = 0.07352771610021591\n",
      "Iteration 2000: loss = 0.06857632100582123\n",
      "Iteration 2200: loss = 0.06393638253211975\n",
      "Iteration 2400: loss = 0.05986025929450989\n",
      "Iteration 2600: loss = 0.05608617141842842\n",
      "Iteration 2800: loss = 0.05233117938041687\n",
      "Iteration 3000: loss = 0.04842590168118477\n",
      "Iteration 3200: loss = 0.04437310993671417\n",
      "Iteration 3400: loss = 0.0401720330119133\n",
      "Iteration 3600: loss = 0.035950712859630585\n",
      "Iteration 3800: loss = 0.03187166154384613\n",
      "Iteration 4000: loss = 0.028101250529289246\n",
      "Iteration 4200: loss = 0.024724559858441353\n",
      "Iteration 4400: loss = 0.021777579560875893\n",
      "Iteration 4600: loss = 0.01930055022239685\n",
      "Iteration 4800: loss = 0.01722867600619793\n",
      "Iteration 5000: loss = 0.015497439540922642\n",
      "Iteration 5200: loss = 0.014042545109987259\n",
      "Iteration 5400: loss = 0.01281693298369646\n",
      "Iteration 5600: loss = 0.011777420528233051\n",
      "Iteration 5800: loss = 0.01088547520339489\n",
      "Iteration 6000: loss = 0.010111100971698761\n",
      "Iteration 6200: loss = 0.009430870413780212\n",
      "Iteration 6400: loss = 0.008826525881886482\n",
      "Iteration 6600: loss = 0.00828541535884142\n",
      "Iteration 6800: loss = 0.007796930614858866\n",
      "Iteration 7000: loss = 0.007353474386036396\n",
      "Iteration 7200: loss = 0.006955198477953672\n",
      "Iteration 7400: loss = 0.006596492603421211\n",
      "Iteration 7600: loss = 0.006271339952945709\n",
      "Iteration 7800: loss = 0.005974155385047197\n",
      "Iteration 8000: loss = 0.005699892528355122\n",
      "Iteration 8200: loss = 0.005444471724331379\n",
      "Iteration 8400: loss = 0.005206543952226639\n",
      "Iteration 8600: loss = 0.004978749435395002\n",
      "Iteration 8800: loss = 0.004773070104420185\n",
      "Iteration 9000: loss = 0.0045857783406972885\n",
      "Iteration 9200: loss = 0.004412030801177025\n",
      "Iteration 9400: loss = 0.004248831421136856\n",
      "Iteration 9600: loss = 0.004094691947102547\n",
      "Iteration 9800: loss = 0.003951597027480602\n",
      "Iteration 10000: loss = 0.0038191191852092743\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    L = loss(net.forward(x_data), y_data)\n",
    "    optimizer.zero_grad()\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "    if (i+1) % 500 == 0:\n",
    "        print(\"Iteration {0}: loss = {1}\".format(i+1, L.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.0\n"
     ]
    }
   ],
   "source": [
    "res = net.forward(x_data).round().detach().numpy()\n",
    "true_res = np.array(y_data)\n",
    "print(np.sum(np.abs(res - true_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
